{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入需要使用的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用CUDA设备，并配置超参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "image_size = 784\n",
    "h_dim = 400\n",
    "z_dim = 20\n",
    "num_epochs = 15\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建sample文件夹。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dir = 'samples'\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "载入MNIST数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.MNIST(root='../../data',\n",
    "                                     train=True,\n",
    "                                     transform=transforms.ToTensor(),\n",
    "                                     download=True)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建一个变分自编码网络([VAE](https://www.cnblogs.com/huangshiyu13/p/6209016.html))，VAE的机构为：\n",
    "\n",
    "<div align=center><img src=\"https://images2015.cnblogs.com/blog/798706/201612/798706-20161222110521495-412598726.png\" alt=\"\" width=\"663\" height=\"255\"></div>\n",
    "\n",
    "由于模型有重构的loss还有训练mu和std的loss,所以`forward`函数的返回是有3个的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_size=784, h_dim=400, z_dim=20):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(image_size, h_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc3 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim)\n",
    "        self.fc5 = nn.Linear(h_dim, image_size)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        return self.fc2(h), self.fc3(h)\n",
    "    \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(log_var/2)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        return F.sigmoid(self.fc5(h))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_reconst = self.decode(z)\n",
    "        return x_reconst, mu, log_var\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建一个模型实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练情况："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/15], Step [100/469], Reconst Loss: 11171.4082, KL Div: 3155.0068\n",
      "Epoch[1/15], Step [200/469], Reconst Loss: 11525.8750, KL Div: 3125.1724\n",
      "Epoch[1/15], Step [300/469], Reconst Loss: 11003.8467, KL Div: 3157.7600\n",
      "Epoch[1/15], Step [400/469], Reconst Loss: 10961.0156, KL Div: 3120.3181\n",
      "Epoch[2/15], Step [100/469], Reconst Loss: 10916.7617, KL Div: 3129.7771\n",
      "Epoch[2/15], Step [200/469], Reconst Loss: 11275.9414, KL Div: 3250.2090\n",
      "Epoch[2/15], Step [300/469], Reconst Loss: 10692.9727, KL Div: 3192.1187\n",
      "Epoch[2/15], Step [400/469], Reconst Loss: 11021.7539, KL Div: 3186.9519\n",
      "Epoch[3/15], Step [100/469], Reconst Loss: 10616.5264, KL Div: 3076.5391\n",
      "Epoch[3/15], Step [200/469], Reconst Loss: 10710.6719, KL Div: 3238.9351\n",
      "Epoch[3/15], Step [300/469], Reconst Loss: 10225.2607, KL Div: 3118.9282\n",
      "Epoch[3/15], Step [400/469], Reconst Loss: 10488.7637, KL Div: 3151.3682\n",
      "Epoch[4/15], Step [100/469], Reconst Loss: 10261.7764, KL Div: 3143.8379\n",
      "Epoch[4/15], Step [200/469], Reconst Loss: 10625.1211, KL Div: 3162.8999\n",
      "Epoch[4/15], Step [300/469], Reconst Loss: 10520.5098, KL Div: 3183.8850\n",
      "Epoch[4/15], Step [400/469], Reconst Loss: 10587.6338, KL Div: 3165.3369\n",
      "Epoch[5/15], Step [100/469], Reconst Loss: 10430.1914, KL Div: 3341.6892\n",
      "Epoch[5/15], Step [200/469], Reconst Loss: 10215.8203, KL Div: 3024.5723\n",
      "Epoch[5/15], Step [300/469], Reconst Loss: 11128.1699, KL Div: 3322.4141\n",
      "Epoch[5/15], Step [400/469], Reconst Loss: 10537.4414, KL Div: 3247.3408\n",
      "Epoch[6/15], Step [100/469], Reconst Loss: 10549.8945, KL Div: 3361.3027\n",
      "Epoch[6/15], Step [200/469], Reconst Loss: 10557.0244, KL Div: 3366.9956\n",
      "Epoch[6/15], Step [300/469], Reconst Loss: 10582.2734, KL Div: 3185.1328\n",
      "Epoch[6/15], Step [400/469], Reconst Loss: 10295.1377, KL Div: 3248.3799\n",
      "Epoch[7/15], Step [100/469], Reconst Loss: 10282.2227, KL Div: 3279.1191\n",
      "Epoch[7/15], Step [200/469], Reconst Loss: 10270.9404, KL Div: 3148.4727\n",
      "Epoch[7/15], Step [300/469], Reconst Loss: 10841.8184, KL Div: 3320.6079\n",
      "Epoch[7/15], Step [400/469], Reconst Loss: 10368.7227, KL Div: 3176.5635\n",
      "Epoch[8/15], Step [100/469], Reconst Loss: 10280.1289, KL Div: 3212.3833\n",
      "Epoch[8/15], Step [200/469], Reconst Loss: 10449.6904, KL Div: 3269.5576\n",
      "Epoch[8/15], Step [300/469], Reconst Loss: 10388.0723, KL Div: 3291.4028\n",
      "Epoch[8/15], Step [400/469], Reconst Loss: 10234.0020, KL Div: 3247.5698\n",
      "Epoch[9/15], Step [100/469], Reconst Loss: 9937.0498, KL Div: 3161.9946\n",
      "Epoch[9/15], Step [200/469], Reconst Loss: 10539.2441, KL Div: 3285.0366\n",
      "Epoch[9/15], Step [300/469], Reconst Loss: 10295.1670, KL Div: 3306.7700\n",
      "Epoch[9/15], Step [400/469], Reconst Loss: 10411.2822, KL Div: 3295.3943\n",
      "Epoch[10/15], Step [100/469], Reconst Loss: 10551.0547, KL Div: 3312.1760\n",
      "Epoch[10/15], Step [200/469], Reconst Loss: 10242.9297, KL Div: 3183.5945\n",
      "Epoch[10/15], Step [300/469], Reconst Loss: 10339.3291, KL Div: 3334.5095\n",
      "Epoch[10/15], Step [400/469], Reconst Loss: 10520.4629, KL Div: 3334.1812\n",
      "Epoch[11/15], Step [100/469], Reconst Loss: 10276.9004, KL Div: 3310.6509\n",
      "Epoch[11/15], Step [200/469], Reconst Loss: 10037.4180, KL Div: 3302.7778\n",
      "Epoch[11/15], Step [300/469], Reconst Loss: 10473.0342, KL Div: 3248.5906\n",
      "Epoch[11/15], Step [400/469], Reconst Loss: 10448.9766, KL Div: 3210.2576\n",
      "Epoch[12/15], Step [100/469], Reconst Loss: 10105.1934, KL Div: 3225.3853\n",
      "Epoch[12/15], Step [200/469], Reconst Loss: 9922.1309, KL Div: 3188.1392\n",
      "Epoch[12/15], Step [300/469], Reconst Loss: 10498.8926, KL Div: 3211.2903\n",
      "Epoch[12/15], Step [400/469], Reconst Loss: 10850.9619, KL Div: 3410.2266\n",
      "Epoch[13/15], Step [100/469], Reconst Loss: 10372.5049, KL Div: 3344.2434\n",
      "Epoch[13/15], Step [200/469], Reconst Loss: 9884.4668, KL Div: 3236.0244\n",
      "Epoch[13/15], Step [300/469], Reconst Loss: 9925.2705, KL Div: 3293.3228\n",
      "Epoch[13/15], Step [400/469], Reconst Loss: 10590.0410, KL Div: 3333.6895\n",
      "Epoch[14/15], Step [100/469], Reconst Loss: 10479.5059, KL Div: 3344.0176\n",
      "Epoch[14/15], Step [200/469], Reconst Loss: 9784.4414, KL Div: 3241.3892\n",
      "Epoch[14/15], Step [300/469], Reconst Loss: 10325.9736, KL Div: 3189.8232\n",
      "Epoch[14/15], Step [400/469], Reconst Loss: 9945.2695, KL Div: 3299.4448\n",
      "Epoch[15/15], Step [100/469], Reconst Loss: 10101.4023, KL Div: 3299.7222\n",
      "Epoch[15/15], Step [200/469], Reconst Loss: 10144.7627, KL Div: 3286.5825\n",
      "Epoch[15/15], Step [300/469], Reconst Loss: 10187.7354, KL Div: 3291.4146\n",
      "Epoch[15/15], Step [400/469], Reconst Loss: 10026.6260, KL Div: 3304.6499\n"
     ]
    }
   ],
   "source": [
    "# 训练主循环\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (x, _) in enumerate(data_loader):\n",
    "        # 前向计算，模型的输出是最后一层，以及编码的mu和std\n",
    "        x = x.to(device).view(-1, image_size)\n",
    "        x_reconst, mu, log_var = model(x)\n",
    "        \n",
    "        # 重构误差计算\n",
    "        # KL误差参考http://yunjey47.tistory.com/43 或者VAE论文的附录B\n",
    "        reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False)\n",
    "        kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        \n",
    "        # 反向传播\n",
    "        loss = reconst_loss + kl_div\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print (\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}\" \n",
    "                   .format(epoch+1, num_epochs, i+1, len(data_loader), reconst_loss.item(), kl_div.item()))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # 保存采样图像\n",
    "        z = torch.randn(batch_size, z_dim).to(device)\n",
    "        out = model.decode(z).view(-1, 1, 28, 28)\n",
    "        save_image(out, os.path.join(sample_dir, 'sampled-{}.png'.format(epoch+1)))\n",
    "\n",
    "        # 保存生成图像\n",
    "        out, _, _ = model(x)\n",
    "        x_concat = torch.cat([x.view(-1, 1, 28, 28), out.view(-1, 1, 28, 28)], dim=3)\n",
    "        save_image(x_concat, os.path.join(sample_dir, 'reconst-{}.png'.format(epoch+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
