{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard是个好东西，可以可视化训练结果，在使用tensorboard或者keras时候经常使用这个工具。先看下`logger.py`文件。定义一个Logger类，里面的函数分别是：\n",
    " - `__init__`：构造函数，需要log_dir作为参数，如果不存在这个文件夹就生成\n",
    " - scalar_summary：写入一个标量数据，分别是tag, value, step作为参数\n",
    " - image_summary：写入一张图像，参数同scalar_summary\n",
    " - histo_summary：矩阵数据?多用于可视化参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code referenced from https://gist.github.com/gyglim/1f8dfb1b5c82627ae3efcfbbadb9f514\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.misc \n",
    "try:\n",
    "    from StringIO import StringIO  # Python 2.7\n",
    "except ImportError:\n",
    "    from io import BytesIO         # Python 3.x\n",
    "\n",
    "\n",
    "class Logger(object):\n",
    "    \n",
    "    def __init__(self, log_dir):\n",
    "        \"\"\"Create a summary writer logging to log_dir.\"\"\"\n",
    "        self.writer = tf.summary.FileWriter(log_dir)\n",
    "\n",
    "    def scalar_summary(self, tag, value, step):\n",
    "        \"\"\"Log a scalar variable.\"\"\"\n",
    "        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, simple_value=value)])\n",
    "        self.writer.add_summary(summary, step)\n",
    "\n",
    "    def image_summary(self, tag, images, step):\n",
    "        \"\"\"Log a list of images.\"\"\"\n",
    "\n",
    "        img_summaries = []\n",
    "        for i, img in enumerate(images):\n",
    "            # Write the image to a string\n",
    "            try:\n",
    "                s = StringIO()\n",
    "            except:\n",
    "                s = BytesIO()\n",
    "            scipy.misc.toimage(img).save(s, format=\"png\")\n",
    "\n",
    "            # Create an Image object\n",
    "            img_sum = tf.Summary.Image(encoded_image_string=s.getvalue(),\n",
    "                                       height=img.shape[0],\n",
    "                                       width=img.shape[1])\n",
    "            # Create a Summary value\n",
    "            img_summaries.append(tf.Summary.Value(tag='%s/%d' % (tag, i), image=img_sum))\n",
    "\n",
    "        # Create and write Summary\n",
    "        summary = tf.Summary(value=img_summaries)\n",
    "        self.writer.add_summary(summary, step)\n",
    "        \n",
    "    def histo_summary(self, tag, values, step, bins=1000):\n",
    "        \"\"\"Log a histogram of the tensor of values.\"\"\"\n",
    "\n",
    "        # Create a histogram using numpy\n",
    "        counts, bin_edges = np.histogram(values, bins=bins)\n",
    "\n",
    "        # Fill the fields of the histogram proto\n",
    "        hist = tf.HistogramProto()\n",
    "        hist.min = float(np.min(values))\n",
    "        hist.max = float(np.max(values))\n",
    "        hist.num = int(np.prod(values.shape))\n",
    "        hist.sum = float(np.sum(values))\n",
    "        hist.sum_squares = float(np.sum(values**2))\n",
    "\n",
    "        # Drop the start of the first bin\n",
    "        bin_edges = bin_edges[1:]\n",
    "\n",
    "        # Add bin edges and counts\n",
    "        for edge in bin_edges:\n",
    "            hist.bucket_limit.append(edge)\n",
    "        for c in counts:\n",
    "            hist.bucket.append(c)\n",
    "\n",
    "        # Create and write Summary\n",
    "        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, histo=hist)])\n",
    "        self.writer.add_summary(summary, step)\n",
    "        self.writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用一个简单的网络看下Tensorboard如何使用，还是先导入相应的包文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用MNIST数据集，导入数据集，并生成DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                     train=True, \n",
    "                                     transform=transforms.ToTensor(),  \n",
    "                                     download=True)\n",
    "\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义一个只有一个隐藏层的全连接网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size=784, hidden_size=500, num_classes=10):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建一个网络对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**创建一个Logger对象。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = Logger('./logs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义优化器和损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)  \n",
    "\n",
    "data_iter = iter(data_loader)\n",
    "iter_per_epoch = len(data_loader)\n",
    "total_step = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [100/50000], Loss: 2.2100, Acc: 0.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: DeprecationWarning: `toimage` is deprecated!\n",
      "`toimage` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use Pillow's ``Image.fromarray`` directly instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [200/50000], Loss: 2.1023, Acc: 0.63\n",
      "Step [300/50000], Loss: 1.9762, Acc: 0.75\n",
      "Step [400/50000], Loss: 1.8005, Acc: 0.82\n",
      "Step [500/50000], Loss: 1.7678, Acc: 0.77\n",
      "Step [600/50000], Loss: 1.5943, Acc: 0.81\n",
      "Step [700/50000], Loss: 1.4049, Acc: 0.84\n",
      "Step [800/50000], Loss: 1.2297, Acc: 0.80\n",
      "Step [900/50000], Loss: 1.2623, Acc: 0.83\n",
      "Step [1000/50000], Loss: 1.1100, Acc: 0.86\n",
      "Step [1100/50000], Loss: 1.0732, Acc: 0.80\n",
      "Step [1200/50000], Loss: 1.1394, Acc: 0.81\n",
      "Step [1300/50000], Loss: 1.1252, Acc: 0.76\n",
      "Step [1400/50000], Loss: 0.8352, Acc: 0.85\n",
      "Step [1500/50000], Loss: 0.9541, Acc: 0.77\n",
      "Step [1600/50000], Loss: 0.7346, Acc: 0.93\n",
      "Step [1700/50000], Loss: 0.8345, Acc: 0.83\n",
      "Step [1800/50000], Loss: 0.7983, Acc: 0.83\n",
      "Step [1900/50000], Loss: 0.6986, Acc: 0.90\n",
      "Step [2000/50000], Loss: 0.7485, Acc: 0.80\n",
      "Step [2100/50000], Loss: 0.6486, Acc: 0.85\n",
      "Step [2200/50000], Loss: 0.5744, Acc: 0.87\n",
      "Step [2300/50000], Loss: 0.6069, Acc: 0.88\n",
      "Step [2400/50000], Loss: 0.4930, Acc: 0.94\n",
      "Step [2500/50000], Loss: 0.6676, Acc: 0.83\n",
      "Step [2600/50000], Loss: 0.4610, Acc: 0.94\n",
      "Step [2700/50000], Loss: 0.5379, Acc: 0.88\n",
      "Step [2800/50000], Loss: 0.5355, Acc: 0.89\n",
      "Step [2900/50000], Loss: 0.4580, Acc: 0.91\n",
      "Step [3000/50000], Loss: 0.4852, Acc: 0.92\n",
      "Step [3100/50000], Loss: 0.5255, Acc: 0.86\n",
      "Step [3200/50000], Loss: 0.4036, Acc: 0.94\n",
      "Step [3300/50000], Loss: 0.4799, Acc: 0.87\n",
      "Step [3400/50000], Loss: 0.4382, Acc: 0.93\n",
      "Step [3500/50000], Loss: 0.4078, Acc: 0.91\n",
      "Step [3600/50000], Loss: 0.4525, Acc: 0.86\n",
      "Step [3700/50000], Loss: 0.4249, Acc: 0.91\n",
      "Step [3800/50000], Loss: 0.5104, Acc: 0.90\n",
      "Step [3900/50000], Loss: 0.4573, Acc: 0.86\n",
      "Step [4000/50000], Loss: 0.5504, Acc: 0.83\n",
      "Step [4100/50000], Loss: 0.3377, Acc: 0.93\n",
      "Step [4200/50000], Loss: 0.5159, Acc: 0.88\n",
      "Step [4300/50000], Loss: 0.6212, Acc: 0.83\n",
      "Step [4400/50000], Loss: 0.3703, Acc: 0.88\n",
      "Step [4500/50000], Loss: 0.4237, Acc: 0.90\n",
      "Step [4600/50000], Loss: 0.3603, Acc: 0.92\n",
      "Step [4700/50000], Loss: 0.4024, Acc: 0.88\n",
      "Step [4800/50000], Loss: 0.3653, Acc: 0.92\n",
      "Step [4900/50000], Loss: 0.2605, Acc: 0.97\n",
      "Step [5000/50000], Loss: 0.3583, Acc: 0.92\n",
      "Step [5100/50000], Loss: 0.3546, Acc: 0.89\n",
      "Step [5200/50000], Loss: 0.4561, Acc: 0.85\n",
      "Step [5300/50000], Loss: 0.4355, Acc: 0.87\n",
      "Step [5400/50000], Loss: 0.3033, Acc: 0.93\n",
      "Step [5500/50000], Loss: 0.2722, Acc: 0.94\n",
      "Step [5600/50000], Loss: 0.4240, Acc: 0.89\n",
      "Step [5700/50000], Loss: 0.4030, Acc: 0.90\n",
      "Step [5800/50000], Loss: 0.3919, Acc: 0.86\n",
      "Step [5900/50000], Loss: 0.3586, Acc: 0.91\n",
      "Step [6000/50000], Loss: 0.3490, Acc: 0.91\n",
      "Step [6100/50000], Loss: 0.4762, Acc: 0.84\n",
      "Step [6200/50000], Loss: 0.3963, Acc: 0.94\n",
      "Step [6300/50000], Loss: 0.3710, Acc: 0.88\n",
      "Step [6400/50000], Loss: 0.4053, Acc: 0.91\n",
      "Step [6500/50000], Loss: 0.4214, Acc: 0.87\n",
      "Step [6600/50000], Loss: 0.2912, Acc: 0.87\n",
      "Step [6700/50000], Loss: 0.3335, Acc: 0.89\n",
      "Step [6800/50000], Loss: 0.2943, Acc: 0.92\n",
      "Step [6900/50000], Loss: 0.4268, Acc: 0.88\n",
      "Step [7000/50000], Loss: 0.1680, Acc: 0.97\n",
      "Step [7100/50000], Loss: 0.4091, Acc: 0.85\n",
      "Step [7200/50000], Loss: 0.4236, Acc: 0.87\n",
      "Step [7300/50000], Loss: 0.2795, Acc: 0.93\n",
      "Step [7400/50000], Loss: 0.4096, Acc: 0.89\n",
      "Step [7500/50000], Loss: 0.3336, Acc: 0.91\n",
      "Step [7600/50000], Loss: 0.2892, Acc: 0.88\n",
      "Step [7700/50000], Loss: 0.2750, Acc: 0.92\n",
      "Step [7800/50000], Loss: 0.2143, Acc: 0.93\n",
      "Step [7900/50000], Loss: 0.3392, Acc: 0.91\n",
      "Step [8000/50000], Loss: 0.3235, Acc: 0.88\n",
      "Step [8100/50000], Loss: 0.3567, Acc: 0.91\n",
      "Step [8200/50000], Loss: 0.1716, Acc: 0.96\n",
      "Step [8300/50000], Loss: 0.3450, Acc: 0.90\n",
      "Step [8400/50000], Loss: 0.2695, Acc: 0.94\n",
      "Step [8500/50000], Loss: 0.1537, Acc: 0.98\n",
      "Step [8600/50000], Loss: 0.3541, Acc: 0.91\n",
      "Step [8700/50000], Loss: 0.2938, Acc: 0.93\n",
      "Step [8800/50000], Loss: 0.3361, Acc: 0.90\n",
      "Step [8900/50000], Loss: 0.2718, Acc: 0.93\n",
      "Step [9000/50000], Loss: 0.1667, Acc: 0.96\n",
      "Step [9100/50000], Loss: 0.2091, Acc: 0.95\n",
      "Step [9200/50000], Loss: 0.4762, Acc: 0.90\n",
      "Step [9300/50000], Loss: 0.3240, Acc: 0.91\n",
      "Step [9400/50000], Loss: 0.1815, Acc: 0.95\n",
      "Step [9500/50000], Loss: 0.3475, Acc: 0.91\n",
      "Step [9600/50000], Loss: 0.2555, Acc: 0.90\n",
      "Step [9700/50000], Loss: 0.3687, Acc: 0.91\n",
      "Step [9800/50000], Loss: 0.2037, Acc: 0.94\n",
      "Step [9900/50000], Loss: 0.3548, Acc: 0.90\n",
      "Step [10000/50000], Loss: 0.3055, Acc: 0.91\n",
      "Step [10100/50000], Loss: 0.2926, Acc: 0.88\n",
      "Step [10200/50000], Loss: 0.4590, Acc: 0.84\n",
      "Step [10300/50000], Loss: 0.4013, Acc: 0.87\n",
      "Step [10400/50000], Loss: 0.2924, Acc: 0.90\n",
      "Step [10500/50000], Loss: 0.2822, Acc: 0.95\n",
      "Step [10600/50000], Loss: 0.2705, Acc: 0.93\n",
      "Step [10700/50000], Loss: 0.2088, Acc: 0.95\n",
      "Step [10800/50000], Loss: 0.2177, Acc: 0.93\n",
      "Step [10900/50000], Loss: 0.3507, Acc: 0.87\n",
      "Step [11000/50000], Loss: 0.2231, Acc: 0.92\n",
      "Step [11100/50000], Loss: 0.1631, Acc: 0.94\n",
      "Step [11200/50000], Loss: 0.2054, Acc: 0.95\n",
      "Step [11300/50000], Loss: 0.1735, Acc: 0.96\n",
      "Step [11400/50000], Loss: 0.2474, Acc: 0.95\n",
      "Step [11500/50000], Loss: 0.2688, Acc: 0.93\n",
      "Step [11600/50000], Loss: 0.2814, Acc: 0.92\n",
      "Step [11700/50000], Loss: 0.3106, Acc: 0.93\n",
      "Step [11800/50000], Loss: 0.3428, Acc: 0.92\n",
      "Step [11900/50000], Loss: 0.2481, Acc: 0.92\n",
      "Step [12000/50000], Loss: 0.3524, Acc: 0.89\n",
      "Step [12100/50000], Loss: 0.3342, Acc: 0.89\n",
      "Step [12200/50000], Loss: 0.2739, Acc: 0.92\n",
      "Step [12300/50000], Loss: 0.2207, Acc: 0.94\n",
      "Step [12400/50000], Loss: 0.2550, Acc: 0.92\n",
      "Step [12500/50000], Loss: 0.3493, Acc: 0.91\n",
      "Step [12600/50000], Loss: 0.2501, Acc: 0.95\n",
      "Step [12700/50000], Loss: 0.1863, Acc: 0.93\n",
      "Step [12800/50000], Loss: 0.2915, Acc: 0.90\n",
      "Step [12900/50000], Loss: 0.3419, Acc: 0.88\n",
      "Step [13000/50000], Loss: 0.1932, Acc: 0.95\n",
      "Step [13100/50000], Loss: 0.2107, Acc: 0.94\n",
      "Step [13200/50000], Loss: 0.2912, Acc: 0.91\n",
      "Step [13300/50000], Loss: 0.2185, Acc: 0.92\n",
      "Step [13400/50000], Loss: 0.2797, Acc: 0.90\n",
      "Step [13500/50000], Loss: 0.2271, Acc: 0.94\n",
      "Step [13600/50000], Loss: 0.2329, Acc: 0.94\n",
      "Step [13700/50000], Loss: 0.3353, Acc: 0.90\n",
      "Step [13800/50000], Loss: 0.2522, Acc: 0.94\n",
      "Step [13900/50000], Loss: 0.2282, Acc: 0.94\n",
      "Step [14000/50000], Loss: 0.2165, Acc: 0.95\n",
      "Step [14100/50000], Loss: 0.3817, Acc: 0.89\n",
      "Step [14200/50000], Loss: 0.2932, Acc: 0.94\n",
      "Step [14300/50000], Loss: 0.3816, Acc: 0.84\n",
      "Step [14400/50000], Loss: 0.2395, Acc: 0.91\n",
      "Step [14500/50000], Loss: 0.3547, Acc: 0.91\n",
      "Step [14600/50000], Loss: 0.2672, Acc: 0.93\n",
      "Step [14700/50000], Loss: 0.2570, Acc: 0.94\n",
      "Step [14800/50000], Loss: 0.2242, Acc: 0.96\n",
      "Step [14900/50000], Loss: 0.1326, Acc: 0.97\n",
      "Step [15000/50000], Loss: 0.1620, Acc: 0.97\n",
      "Step [15100/50000], Loss: 0.2867, Acc: 0.90\n",
      "Step [15200/50000], Loss: 0.2172, Acc: 0.96\n",
      "Step [15300/50000], Loss: 0.1995, Acc: 0.95\n",
      "Step [15400/50000], Loss: 0.2513, Acc: 0.93\n",
      "Step [15500/50000], Loss: 0.1973, Acc: 0.95\n",
      "Step [15600/50000], Loss: 0.2331, Acc: 0.92\n",
      "Step [15700/50000], Loss: 0.2962, Acc: 0.87\n",
      "Step [15800/50000], Loss: 0.1173, Acc: 0.97\n",
      "Step [15900/50000], Loss: 0.1754, Acc: 0.97\n",
      "Step [16000/50000], Loss: 0.2478, Acc: 0.91\n",
      "Step [16100/50000], Loss: 0.3050, Acc: 0.89\n",
      "Step [16200/50000], Loss: 0.2827, Acc: 0.90\n",
      "Step [16300/50000], Loss: 0.2269, Acc: 0.93\n",
      "Step [16400/50000], Loss: 0.2627, Acc: 0.92\n",
      "Step [16500/50000], Loss: 0.2899, Acc: 0.92\n",
      "Step [16600/50000], Loss: 0.4013, Acc: 0.88\n",
      "Step [16700/50000], Loss: 0.2579, Acc: 0.93\n",
      "Step [16800/50000], Loss: 0.2963, Acc: 0.91\n",
      "Step [16900/50000], Loss: 0.2515, Acc: 0.93\n",
      "Step [17000/50000], Loss: 0.3460, Acc: 0.89\n",
      "Step [17100/50000], Loss: 0.2692, Acc: 0.96\n",
      "Step [17200/50000], Loss: 0.1369, Acc: 0.96\n",
      "Step [17300/50000], Loss: 0.2900, Acc: 0.90\n",
      "Step [17400/50000], Loss: 0.2258, Acc: 0.93\n",
      "Step [17500/50000], Loss: 0.2459, Acc: 0.93\n",
      "Step [17600/50000], Loss: 0.2362, Acc: 0.94\n",
      "Step [17700/50000], Loss: 0.2486, Acc: 0.96\n",
      "Step [17800/50000], Loss: 0.2647, Acc: 0.94\n",
      "Step [17900/50000], Loss: 0.3410, Acc: 0.93\n",
      "Step [18000/50000], Loss: 0.2144, Acc: 0.95\n",
      "Step [18100/50000], Loss: 0.3345, Acc: 0.92\n",
      "Step [18200/50000], Loss: 0.2829, Acc: 0.94\n",
      "Step [18300/50000], Loss: 0.1659, Acc: 0.96\n",
      "Step [18400/50000], Loss: 0.2597, Acc: 0.93\n",
      "Step [18500/50000], Loss: 0.2784, Acc: 0.94\n",
      "Step [18600/50000], Loss: 0.2504, Acc: 0.93\n",
      "Step [18700/50000], Loss: 0.2802, Acc: 0.92\n",
      "Step [18800/50000], Loss: 0.2556, Acc: 0.95\n",
      "Step [18900/50000], Loss: 0.1760, Acc: 0.96\n",
      "Step [19000/50000], Loss: 0.2213, Acc: 0.93\n",
      "Step [19100/50000], Loss: 0.2371, Acc: 0.92\n",
      "Step [19200/50000], Loss: 0.2254, Acc: 0.93\n",
      "Step [19300/50000], Loss: 0.2013, Acc: 0.94\n",
      "Step [19400/50000], Loss: 0.3813, Acc: 0.89\n",
      "Step [19500/50000], Loss: 0.2942, Acc: 0.95\n",
      "Step [19600/50000], Loss: 0.2686, Acc: 0.93\n",
      "Step [19700/50000], Loss: 0.1368, Acc: 0.97\n",
      "Step [19800/50000], Loss: 0.3173, Acc: 0.89\n",
      "Step [19900/50000], Loss: 0.1752, Acc: 0.95\n",
      "Step [20000/50000], Loss: 0.1596, Acc: 0.95\n",
      "Step [20100/50000], Loss: 0.1460, Acc: 0.97\n",
      "Step [20200/50000], Loss: 0.1953, Acc: 0.95\n",
      "Step [20300/50000], Loss: 0.2630, Acc: 0.92\n",
      "Step [20400/50000], Loss: 0.2303, Acc: 0.93\n",
      "Step [20500/50000], Loss: 0.2172, Acc: 0.94\n",
      "Step [20600/50000], Loss: 0.2558, Acc: 0.94\n",
      "Step [20700/50000], Loss: 0.2091, Acc: 0.93\n",
      "Step [20800/50000], Loss: 0.2671, Acc: 0.95\n",
      "Step [20900/50000], Loss: 0.0732, Acc: 1.00\n",
      "Step [21000/50000], Loss: 0.3352, Acc: 0.91\n",
      "Step [21100/50000], Loss: 0.2516, Acc: 0.91\n",
      "Step [21200/50000], Loss: 0.1687, Acc: 0.98\n",
      "Step [21300/50000], Loss: 0.2124, Acc: 0.96\n",
      "Step [21400/50000], Loss: 0.2571, Acc: 0.91\n",
      "Step [21500/50000], Loss: 0.2118, Acc: 0.97\n",
      "Step [21600/50000], Loss: 0.2057, Acc: 0.95\n",
      "Step [21700/50000], Loss: 0.3150, Acc: 0.94\n",
      "Step [21800/50000], Loss: 0.1858, Acc: 0.95\n",
      "Step [21900/50000], Loss: 0.2291, Acc: 0.92\n",
      "Step [22000/50000], Loss: 0.1580, Acc: 0.94\n",
      "Step [22100/50000], Loss: 0.1583, Acc: 0.94\n",
      "Step [22200/50000], Loss: 0.2591, Acc: 0.91\n",
      "Step [22300/50000], Loss: 0.1326, Acc: 0.97\n",
      "Step [22400/50000], Loss: 0.2540, Acc: 0.92\n",
      "Step [22500/50000], Loss: 0.2780, Acc: 0.89\n",
      "Step [22600/50000], Loss: 0.3735, Acc: 0.85\n",
      "Step [22700/50000], Loss: 0.3216, Acc: 0.91\n",
      "Step [22800/50000], Loss: 0.2074, Acc: 0.93\n",
      "Step [22900/50000], Loss: 0.1749, Acc: 0.96\n",
      "Step [23000/50000], Loss: 0.1288, Acc: 0.98\n",
      "Step [23100/50000], Loss: 0.1763, Acc: 0.95\n",
      "Step [23200/50000], Loss: 0.1824, Acc: 0.94\n",
      "Step [23300/50000], Loss: 0.2700, Acc: 0.94\n",
      "Step [23400/50000], Loss: 0.1617, Acc: 0.95\n",
      "Step [23500/50000], Loss: 0.1505, Acc: 0.92\n",
      "Step [23600/50000], Loss: 0.2337, Acc: 0.94\n",
      "Step [23700/50000], Loss: 0.3471, Acc: 0.93\n",
      "Step [23800/50000], Loss: 0.2376, Acc: 0.91\n",
      "Step [23900/50000], Loss: 0.2068, Acc: 0.95\n",
      "Step [24000/50000], Loss: 0.1927, Acc: 0.94\n",
      "Step [24100/50000], Loss: 0.3600, Acc: 0.90\n",
      "Step [24200/50000], Loss: 0.2735, Acc: 0.93\n",
      "Step [24300/50000], Loss: 0.2301, Acc: 0.95\n",
      "Step [24400/50000], Loss: 0.1029, Acc: 0.96\n",
      "Step [24500/50000], Loss: 0.2664, Acc: 0.90\n",
      "Step [24600/50000], Loss: 0.1653, Acc: 0.95\n",
      "Step [24700/50000], Loss: 0.1455, Acc: 0.95\n",
      "Step [24800/50000], Loss: 0.1223, Acc: 0.97\n",
      "Step [24900/50000], Loss: 0.1845, Acc: 0.95\n",
      "Step [25000/50000], Loss: 0.3143, Acc: 0.93\n",
      "Step [25100/50000], Loss: 0.1730, Acc: 0.93\n",
      "Step [25200/50000], Loss: 0.1983, Acc: 0.95\n",
      "Step [25300/50000], Loss: 0.1691, Acc: 0.98\n",
      "Step [25400/50000], Loss: 0.1925, Acc: 0.94\n",
      "Step [25500/50000], Loss: 0.2475, Acc: 0.94\n",
      "Step [25600/50000], Loss: 0.1774, Acc: 0.94\n",
      "Step [25700/50000], Loss: 0.2285, Acc: 0.93\n",
      "Step [25800/50000], Loss: 0.2192, Acc: 0.95\n",
      "Step [25900/50000], Loss: 0.2148, Acc: 0.94\n",
      "Step [26000/50000], Loss: 0.2368, Acc: 0.96\n",
      "Step [26100/50000], Loss: 0.1350, Acc: 0.98\n",
      "Step [26200/50000], Loss: 0.1306, Acc: 0.96\n",
      "Step [26300/50000], Loss: 0.1057, Acc: 0.97\n",
      "Step [26400/50000], Loss: 0.3544, Acc: 0.89\n",
      "Step [26500/50000], Loss: 0.1003, Acc: 0.97\n",
      "Step [26600/50000], Loss: 0.1555, Acc: 0.95\n",
      "Step [26700/50000], Loss: 0.2089, Acc: 0.95\n",
      "Step [26800/50000], Loss: 0.1923, Acc: 0.94\n",
      "Step [26900/50000], Loss: 0.1620, Acc: 0.95\n",
      "Step [27000/50000], Loss: 0.1487, Acc: 0.97\n",
      "Step [27100/50000], Loss: 0.2197, Acc: 0.94\n",
      "Step [27200/50000], Loss: 0.2412, Acc: 0.92\n",
      "Step [27300/50000], Loss: 0.1524, Acc: 0.95\n",
      "Step [27400/50000], Loss: 0.2184, Acc: 0.94\n",
      "Step [27500/50000], Loss: 0.1186, Acc: 0.96\n",
      "Step [27600/50000], Loss: 0.1961, Acc: 0.93\n",
      "Step [27700/50000], Loss: 0.1793, Acc: 0.95\n",
      "Step [27800/50000], Loss: 0.1872, Acc: 0.93\n",
      "Step [27900/50000], Loss: 0.1311, Acc: 0.96\n",
      "Step [28000/50000], Loss: 0.1526, Acc: 0.96\n",
      "Step [28100/50000], Loss: 0.0735, Acc: 1.00\n",
      "Step [28200/50000], Loss: 0.1841, Acc: 0.93\n",
      "Step [28300/50000], Loss: 0.1022, Acc: 0.97\n",
      "Step [28400/50000], Loss: 0.1347, Acc: 0.96\n",
      "Step [28500/50000], Loss: 0.1747, Acc: 0.94\n",
      "Step [28600/50000], Loss: 0.2807, Acc: 0.94\n",
      "Step [28700/50000], Loss: 0.4031, Acc: 0.91\n",
      "Step [28800/50000], Loss: 0.3922, Acc: 0.90\n",
      "Step [28900/50000], Loss: 0.1428, Acc: 0.96\n",
      "Step [29000/50000], Loss: 0.2923, Acc: 0.91\n",
      "Step [29100/50000], Loss: 0.1309, Acc: 0.98\n",
      "Step [29200/50000], Loss: 0.0963, Acc: 0.98\n",
      "Step [29300/50000], Loss: 0.3546, Acc: 0.89\n",
      "Step [29400/50000], Loss: 0.1470, Acc: 0.94\n",
      "Step [29500/50000], Loss: 0.1629, Acc: 0.95\n",
      "Step [29600/50000], Loss: 0.1440, Acc: 0.97\n",
      "Step [29700/50000], Loss: 0.1433, Acc: 0.97\n",
      "Step [29800/50000], Loss: 0.1138, Acc: 0.96\n",
      "Step [29900/50000], Loss: 0.1920, Acc: 0.98\n",
      "Step [30000/50000], Loss: 0.1418, Acc: 0.96\n",
      "Step [30100/50000], Loss: 0.2743, Acc: 0.92\n",
      "Step [30200/50000], Loss: 0.1752, Acc: 0.96\n",
      "Step [30300/50000], Loss: 0.1355, Acc: 0.97\n",
      "Step [30400/50000], Loss: 0.2146, Acc: 0.95\n",
      "Step [30500/50000], Loss: 0.2195, Acc: 0.94\n",
      "Step [30600/50000], Loss: 0.1907, Acc: 0.93\n",
      "Step [30700/50000], Loss: 0.1759, Acc: 0.96\n",
      "Step [30800/50000], Loss: 0.1402, Acc: 0.98\n",
      "Step [30900/50000], Loss: 0.1758, Acc: 0.95\n",
      "Step [31000/50000], Loss: 0.1423, Acc: 0.94\n",
      "Step [31100/50000], Loss: 0.1940, Acc: 0.95\n",
      "Step [31200/50000], Loss: 0.1777, Acc: 0.94\n",
      "Step [31300/50000], Loss: 0.2024, Acc: 0.94\n",
      "Step [31400/50000], Loss: 0.0726, Acc: 0.99\n",
      "Step [31500/50000], Loss: 0.2861, Acc: 0.89\n",
      "Step [31600/50000], Loss: 0.2547, Acc: 0.94\n",
      "Step [31700/50000], Loss: 0.1538, Acc: 0.98\n",
      "Step [31800/50000], Loss: 0.2513, Acc: 0.94\n",
      "Step [31900/50000], Loss: 0.1046, Acc: 0.99\n",
      "Step [32000/50000], Loss: 0.2170, Acc: 0.92\n",
      "Step [32100/50000], Loss: 0.2019, Acc: 0.95\n",
      "Step [32200/50000], Loss: 0.1663, Acc: 0.96\n",
      "Step [32300/50000], Loss: 0.1157, Acc: 0.97\n",
      "Step [32400/50000], Loss: 0.1410, Acc: 0.97\n",
      "Step [32500/50000], Loss: 0.2134, Acc: 0.94\n",
      "Step [32600/50000], Loss: 0.1580, Acc: 0.96\n",
      "Step [32700/50000], Loss: 0.1858, Acc: 0.94\n",
      "Step [32800/50000], Loss: 0.1810, Acc: 0.95\n",
      "Step [32900/50000], Loss: 0.1032, Acc: 0.99\n",
      "Step [33000/50000], Loss: 0.1167, Acc: 0.96\n",
      "Step [33100/50000], Loss: 0.1937, Acc: 0.96\n",
      "Step [33200/50000], Loss: 0.2947, Acc: 0.88\n",
      "Step [33300/50000], Loss: 0.1262, Acc: 0.96\n",
      "Step [33400/50000], Loss: 0.0846, Acc: 0.98\n",
      "Step [33500/50000], Loss: 0.1161, Acc: 0.97\n",
      "Step [33600/50000], Loss: 0.1687, Acc: 0.95\n",
      "Step [33700/50000], Loss: 0.1865, Acc: 0.94\n",
      "Step [33800/50000], Loss: 0.1005, Acc: 0.99\n",
      "Step [33900/50000], Loss: 0.1482, Acc: 0.96\n",
      "Step [34000/50000], Loss: 0.1176, Acc: 0.96\n",
      "Step [34100/50000], Loss: 0.2052, Acc: 0.93\n",
      "Step [34200/50000], Loss: 0.1984, Acc: 0.94\n",
      "Step [34300/50000], Loss: 0.1173, Acc: 0.97\n",
      "Step [34400/50000], Loss: 0.2095, Acc: 0.95\n",
      "Step [34500/50000], Loss: 0.1496, Acc: 0.96\n"
     ]
    }
   ],
   "source": [
    "for step in range(total_step):\n",
    "    \n",
    "    # 重置data_iter\n",
    "    if (step+1) % iter_per_epoch == 0:\n",
    "        data_iter = iter(data_loader)\n",
    "\n",
    "    # 获取训练数据\n",
    "    images, labels = next(data_iter)\n",
    "    images, labels = images.view(images.size(0), -1).to(device), labels.to(device)\n",
    "    \n",
    "    # 前向传播并计算loss\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # 优化参数\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 计算准确率\n",
    "    _, argmax = torch.max(outputs, 1)\n",
    "    accuracy = (labels == argmax.squeeze()).float().mean()\n",
    "\n",
    "    if (step+1) % 100 == 0:\n",
    "        print ('Step [{}/{}], Loss: {:.4f}, Acc: {:.2f}' \n",
    "               .format(step+1, total_step, loss.item(), accuracy.item()))\n",
    "\n",
    "        # ================================================================== #\n",
    "        #                        Tensorboard Logging                         #\n",
    "        # ================================================================== #\n",
    "\n",
    "        # 1. 形成需要写入Tensorboard的数据\n",
    "        info = { 'loss': loss.item(), 'accuracy': accuracy.item() }\n",
    "\n",
    "        # 2. 调用logger.scalar_summary方法写入数据\n",
    "        for tag, value in info.items():\n",
    "            logger.scalar_summary(tag, value, step+1)\n",
    "\n",
    "        # 3. 调用logger.histo_summary保存参数梯度。\n",
    "        for tag, value in model.named_parameters():\n",
    "            tag = tag.replace('.', '/')\n",
    "            logger.histo_summary(tag, value.data.cpu().numpy(), step+1)\n",
    "            logger.histo_summary(tag+'/grad', value.grad.data.cpu().numpy(), step+1)\n",
    "\n",
    "        # 4. 调用logger.image_summary方法写入图像数据\n",
    "        info = { 'images': images.view(-1, 28, 28)[:10].cpu().numpy() }\n",
    "\n",
    "        for tag, images in info.items():\n",
    "            logger.image_summary(tag, images, step+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
